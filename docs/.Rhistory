auto[,i] <- as.numeric(auto[,i])
i <- i + 1
}
#remove all NAs
auto <- na.omit(auto)
#I made a while loop to iterate through each column
i <- 1
while (i <= 7) {
#get each range
column_range <- range(auto[, i])
#print column names all nice and neat
cat("Column:", colnames(auto)[i], "\n")
#print range all nice and neat
cat("Range:", column_range, "\n")
#add blank line
cat("\n")
#iterate
i <- i + 1
}
#I made a while loop to iterate through each column
i <- 1
while (i <= 7) {
#get each mean and std dev
column_mean <- mean(auto[, i])
column_std_dev <- sd(auto[, i])
#print column names all nice and neat
cat("Column:", colnames(auto)[i], "\n")
#print mean & std dev all nice and neat
cat("mean:", column_mean, "\n")
cat("Std Dev:", column_std_dev, "\n")
#add blank line
cat("\n")
#iterate
i <- i + 1
}
#create a new DF that excludes the 10 - 85 rows
auto_sub <- auto[-(10:85),]
#I made a while loop to iterate through each colum
i <- 1
while (i <= 7) {
#get each range
column_range <- range(auto[, i])
#get each mean and std dev
column_mean <- mean(auto[, i])
column_std_dev <- sd(auto[, i])
#print column names all nice and neat
cat("Column:", colnames(auto)[i], "\n")
#print range all nice and neat
cat("Range:", column_range, "\n")
#print mean & std dev all nice and neat
cat("mean:", column_mean, "\n")
cat("Std Dev:", column_std_dev, "\n")
#add blank line
cat("\n")
#iterate
i <- i + 1
}
#make the name variable usable with the pairs() function
auto$name <- as.factor(auto$name)
#create graphs
pairs(auto)
# Set up the layout
par(mfrow = c(1, 2))
# Plot the scatter plot
plot(auto$acceleration, auto$displacement, main = "Acceleration VS Displacement",
xlab = "Acceleration", ylab = "Displacement")
# Fit a linear regression model
fit <- lm(displacement ~ acceleration, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# Plot the scatter plot
plot(auto$acceleration, auto$horsepower, main = "Acceleration VS Horsepower",
xlab = "Acceleration", ylab = "Horsepower")
# Fit a linear regression model
fit <- lm(horsepower ~ acceleration, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
boxplot(mpg ~ cylinders, data = auto, col = "skyblue", main = "Boxplot of mpg VS # of cylinders", xlab = "# of cylinders", ylab = "mpg")
par(mfrow = c(2, 2))
# Plot the scatter plot
plot(auto$mpg, auto$displacement, main = "Acceleration VS Displacement",
xlab = "Acceleration", ylab = "Displacement")
# Fit a linear regression model
fit <- lm(displacement ~ mpg, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# Plot the scatter plot
plot(auto$mpg, auto$horsepower, main = "Acceleration VS Horsepower",
xlab = "Acceleration", ylab = "Horsepower")
# Fit a linear regression model
fit <- lm(horsepower ~ mpg, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# Plot the scatter plot
plot(auto$mpg, auto$weight, main = "Acceleration VS Displacement",
xlab = "Acceleration", ylab = "Displacement")
# Fit a linear regression model
fit <- lm(weight ~ mpg, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# Plot the scatter plot
plot(auto$mpg, auto$year, main = "Acceleration VS Horsepower",
xlab = "Acceleration", ylab = "Horsepower")
# Fit a linear regression model
fit <- lm(year ~ mpg, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# linear regression of horsepower on mpg
fit0 <- lm(mpg ~ horsepower, data = auto)
#show info about linear regression
summary(fit0)
predict <- 39.935861 + (-.157845 * 98)
confint(fit0)
# Plot the scatter plot
plot(auto$acceleration, auto$displacement, main = "Scatter Plot with Trendline",
xlab = "mpg", ylab = "Horsepower")
# Fit a linear regression model
fit <- lm(displacement ~ acceleration, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
plot(fit0)
pairs(auto)
# Exclude the qualitative variable (e.g., "name")
numeric_data <- auto[, sapply(auto, is.numeric)]
# Compute the matrix of correlations
correlation_matrix <- cor(numeric_data)
# Print the correlation matrix
print(correlation_matrix)
# Perform multiple linear regression
model <- lm(mpg ~ . - name, data = auto)
# Print summary of the regression results
summary(model)
# Fit a linear regression model with interaction effect
model_interaction <- lm(mpg ~ year * origin, data = auto)
model_interaction1 <- lm(mpg ~ year * weight, data = auto)
model_interaction2 <- lm(mpg ~ year * horsepower, data = auto)
# Print summary
summary(model_interaction)
summary(model_interaction1)
summary(model_interaction2)
#year * weight had highest R squared, try to improve it
model_interaction3 <- lm(mpg ~ year * horsepower * weight  , data = auto)
summary(model_interaction3)
model_base <- lm(mpg ~ year + origin + weight, data = auto)
# Print summary
summary(model_base)
plot(model_base)
# Fit a linear regression model with variable transformations
model_transformed <- lm(mpg ~ log(year) + sqrt(origin) + I(weight^2), data = auto)
# Print summary
summary(model_transformed)
plot(model_transformed)
?mtcars
# Load the mtcars dataset
data(mtcars)
# Explore the dataset
head(mtcars)  # View the first few rows
summary(mtcars)  # Get summary statistics
# Run a linear model
model <- lm(mpg ~ wt + hp + qsec, data = mtcars)
# Print a summary of the linear model
summary(model)
# turn the first column of college into titles
rownames(college) <- college[, 1]
# importing the college CSV
college <- read.csv("E:\\Obsidian vault\\School Notes\\SP 2024\\Statistical learning\\HW\\DATA\\College.csv")
# turn the first column of college into titles
rownames(college) <- college[, 1]
View(college)
# remove the first column of college df
college <- college[, -1]
View(college)
summary(college)
# private being a string breaks this, so we change it using as.factor
college$Private <- as.factor(college$Private)
pairs(college[,1:10])
# turn the first column of college into titles
rownames(college) <- college[, 1]
# importing the college CSV
college <- read.csv("E:\\Obsidian vault\\School Notes\\SP 2024\\Statistical learning\\HW\\DATA\\College.csv")
# turn the first column of college into titles
rownames(college) <- college[, 1]
View(college)
# remove the first column of college df
college <- college[, -1]
View(college)
summary(college)
# private being a string breaks this, so we change it using as.factor
college$Private <- as.factor(college$Private)
pairs(college[,1:10])
# create plot
plot(Outstate ~ Private, data = college, col = "skyblue", main = "Boxplot of Outstate VS Private", xlab = "Private", ylab = "Outstate")
#initialize Elite
Elite <- rep("No", nrow(college))
#change value to yes if more than 50 percent of students were top 10 percent of HS
Elite[college$Top10perc > 50] <- "Yes"
#turn into a factor
Elite <- as.factor(Elite)
college <- data.frame(college , Elite)
summary(Elite)
#plot
plot(Outstate ~ Elite, data = college, col = "skyblue", main = "Boxplot of Outstate VS Private", xlab = "Elite", ylab = "Outstate")
# Set up the layout
par(mfrow = c(2, 2))
#Graphing
hist(college$Apps, main = "Histogram of Apps (10 bins)", xlab = "Number of Apps", col = "skyblue", breaks = 10)
hist(college$Apps, main = "Histogram of Apps (20 bins)", xlab = "Number of Apps", col = "lightgreen", breaks = 20)
hist(college$perc.alumni, main = "Histogram of perc.alumni (30 bins)", xlab = "per.alumni", col = "lightcoral", breaks = 30)
hist(college$perc.alumni, main = "Histogram of perc.alumni (15 bins)", xlab = "perc.alumni", col = "lightgoldenrodyellow", breaks = 15)
#plotting Expend at elite vs not elite
plot(Expend ~ Elite, data = college, col = "skyblue", main = "Boxplot of Outstate VS Private", xlab = "Elite", ylab = "Expend")
#plotting PhD at elite vs not elite
plot(PhD ~ Elite, data = college, col = "limegreen", main = "Boxplot of Outstate VS Private", xlab = "Elite", ylab = "PhD")
#plotting Grad.Rate at elite vs not elite
plot(Grad.Rate ~ Elite, data = college, col = "goldenrod", main = "Boxplot of Outstate VS Private", xlab = "Elite", ylab = "Grad.Rate")
auto <- read.csv("E:\\Obsidian vault\\School Notes\\SP 2024\\Statistical learning\\HW\\DATA\\Auto.csv")
#iterate through the first 7 columns, making them numeric to turn all non numeric answers in those columns into NA
i <- 1
while (i <= 7) {
auto[,i] <- as.numeric(auto[,i])
i <- i + 1
}
#remove all NAs
auto <- na.omit(auto)
#I made a while loop to iterate through each column
i <- 1
while (i <= 7) {
#get each range
column_range <- range(auto[, i])
#print column names all nice and neat
cat("Column:", colnames(auto)[i], "\n")
#print range all nice and neat
cat("Range:", column_range, "\n")
#add blank line
cat("\n")
#iterate
i <- i + 1
}
#I made a while loop to iterate through each column
i <- 1
while (i <= 7) {
#get each mean and std dev
column_mean <- mean(auto[, i])
column_std_dev <- sd(auto[, i])
#print column names all nice and neat
cat("Column:", colnames(auto)[i], "\n")
#print mean & std dev all nice and neat
cat("mean:", column_mean, "\n")
cat("Std Dev:", column_std_dev, "\n")
#add blank line
cat("\n")
#iterate
i <- i + 1
}
#create a new DF that excludes the 10 - 85 rows
auto_sub <- auto[-(10:85),]
#I made a while loop to iterate through each colum
i <- 1
while (i <= 7) {
#get each range
column_range <- range(auto[, i])
#get each mean and std dev
column_mean <- mean(auto[, i])
column_std_dev <- sd(auto[, i])
#print column names all nice and neat
cat("Column:", colnames(auto)[i], "\n")
#print range all nice and neat
cat("Range:", column_range, "\n")
#print mean & std dev all nice and neat
cat("mean:", column_mean, "\n")
cat("Std Dev:", column_std_dev, "\n")
#add blank line
cat("\n")
#iterate
i <- i + 1
}
#make the name variable usable with the pairs() function
auto$name <- as.factor(auto$name)
#create graphs
pairs(auto)
# Set up the layout
par(mfrow = c(1, 2))
# Plot the scatter plot
plot(auto$acceleration, auto$displacement, main = "Acceleration VS Displacement",
xlab = "Acceleration", ylab = "Displacement")
# Fit a linear regression model
fit <- lm(displacement ~ acceleration, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# Plot the scatter plot
plot(auto$acceleration, auto$horsepower, main = "Acceleration VS Horsepower",
xlab = "Acceleration", ylab = "Horsepower")
# Fit a linear regression model
fit <- lm(horsepower ~ acceleration, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
#creating graph
boxplot(mpg ~ cylinders, data = auto, col = "skyblue", main = "Boxplot of mpg VS # of cylinders", xlab = "# of cylinders", ylab = "mpg")
par(mfrow = c(2, 2))
# Plot the scatter plot
plot(auto$mpg, auto$displacement, main = "Acceleration VS Displacement",
xlab = "Acceleration", ylab = "Displacement")
# Fit a linear regression model
fit <- lm(displacement ~ mpg, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# Plot the scatter plot
plot(auto$mpg, auto$horsepower, main = "Acceleration VS Horsepower",
xlab = "Acceleration", ylab = "Horsepower")
# Fit a linear regression model
fit <- lm(horsepower ~ mpg, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# Plot the scatter plot
plot(auto$mpg, auto$weight, main = "Acceleration VS Displacement",
xlab = "Acceleration", ylab = "Displacement")
# Fit a linear regression model
fit <- lm(weight ~ mpg, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# Plot the scatter plot
plot(auto$mpg, auto$year, main = "Acceleration VS Horsepower",
xlab = "Acceleration", ylab = "Horsepower")
# Fit a linear regression model
fit <- lm(year ~ mpg, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
# linear regression of horsepower on mpg
fit0 <- lm(mpg ~ horsepower, data = auto)
#show info about linear regression
summary(fit0)
#plugging our hypothetical value into our model
predict <- 39.935861 + (-.157845 * 98)
#getting confidence intervals of our model
confint(fit0)
#plugging our hypothetical value into our model
predict <- 39.935861 + (-.157845 * 98)
predict
#getting confidence intervals of our model
confint(fit0)
# Plot the scatter plot
plot(auto$acceleration, auto$displacement, main = "Scatter Plot with Trendline",
xlab = "mpg", ylab = "Horsepower")
# Fit a linear regression model
fit <- lm(displacement ~ acceleration, data = auto)
# Add the trendline to the plot
abline(fit, col = "red")
plot(fit0)
pairs(auto)
# Exclude the qualitative variable (e.g., "name")
numeric_data <- auto[, sapply(auto, is.numeric)]
# Compute the matrix of correlations
correlation_matrix <- cor(numeric_data)
# Print the correlation matrix
print(correlation_matrix)
# Perform multiple linear regression
model <- lm(mpg ~ . - name, data = auto)
# Print summary of the regression results
summary(model)
# Fit a linear regression model with interaction effect
model_interaction <- lm(mpg ~ year * origin, data = auto)
model_interaction1 <- lm(mpg ~ year * weight, data = auto)
model_interaction2 <- lm(mpg ~ year * horsepower, data = auto)
# Print summary
summary(model_interaction)
summary(model_interaction1)
summary(model_interaction2)
#year * weight had highest R squared, try to improve it
model_interaction3 <- lm(mpg ~ year * horsepower * weight  , data = auto)
summary(model_interaction3)
model_base <- lm(mpg ~ year + origin + weight, data = auto)
# Print summary
summary(model_base)
plot(model_base)
# Fit a linear regression model with variable transformations
model_transformed <- lm(mpg ~ log(year) + sqrt(origin) + I(weight^2), data = auto)
# Print summary
summary(model_transformed)
plot(model_transformed)
?mtcars
# Load the mtcars dataset
data(mtcars)
# Explore the dataset
head(mtcars)  # View the first few rows
summary(mtcars)  # Get summary statistics
# Run a linear model
model <- lm(mpg ~ wt + hp + qsec, data = mtcars)
# Print a summary of the linear model
summary(model)
# Run a linear model
model1 <- lm(mpg ~ wt + wt * disp, data = mtcars)
# Print a summary of the linear model
summary(model1)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
udisc_path <- "E:\\Obsidian vault\\Personal Notes\\R\\Projects\\UDISC\\Stats\\Dad2-23-2023.csv"
udisc_stats <- read.csv(udisc_path)
#creating primary key
udisc_stats <- mutate(udisc_stats,
Course_ID = paste(udisc_stats$CourseName, ": ", udisc_stats$LayoutName, ": "))
Just_One_Name <- "Ben"
Just_One_Name
Just_One <- filter(udisc_stats, PlayerName == Just_One_Name)
Just_One
First_hole_Avg <- mean(Just_One$Hole1)
First_hole_Avg
Second_hole_Avg <- mean(Just_One$Hole2)
Second_hole_Avg
Third_hole_Avg <- mean(Just_One$Hole3)
Third_hole_Avg
Fourth_hole_Avg <- mean(Just_One$Hole4)
Fourth_hole_Avg
Fifth_hole_Avg <- mean(Just_One$Hole5)
Fifth_hole_Avg
Sixth_hole_Avg <- mean(Just_One$Hole6)
Sixth_hole_Avg
Seventh_hole_Avg <- mean(Just_One$Hole7)
Seventh_hole_Avg
Eighth_hole_Avg <- mean(Just_One$Hole8)
Eighth_hole_Avg
Ninth_hole_Avg <- mean(Just_One$Hole9)
Ninth_hole_Avg
Front_Nine_Avgs <- c(First_hole_Avg, Second_hole_Avg, Third_hole_Avg, Fourth_hole_Avg, Fifth_hole_Avg, Sixth_hole_Avg, Seventh_hole_Avg, Eighth_hole_Avg, Ninth_hole_Avg)
Front_Nine_Avgs
#create table the combines all courses into one row, and counts number of times played
Playcounts <- group_by(Just_One, Course_ID,) %>%
summarize(
n()
)
Playcounts <- Playcounts %>% distinct(.keep_all = TRUE)
#Just courses played by the main person
Just_One_Course <- c(Playcounts$Course_ID)
#Total number of games played
Total_Games <- as.numeric(nrow(Just_One))
#getting the par for each course played
Pars <- filter(udisc_stats, PlayerName == "Par" )
Pars <- Pars %>% select(-Date)
Pars <- group_by(Pars, Course_ID, Hole1, Hole2, Hole3, Hole4, Hole5, Hole6, Hole7, Hole8, Hole9, Hole10, Hole11, Hole12, Hole13, Hole14, Hole15, Hole16, Hole17, Hole18, Hole19, Hole20, Hole21, Hole22, Hole23, Hole24)
# get rid of dupes
Pars <- Pars[!duplicated(Pars$Course_ID), ]
# THE MAGIC CODE
Pars <- filter(Pars, Course_ID %in% Playcounts$Course_ID)
#ordering pars and Playcounts by Course_ID to get them in the same order
Pars <- Pars[order(Pars$Course_ID), ]
Playcounts <- Playcounts[order(Playcounts$Course_ID), ]
#get weighted average of par for each hole: sum of (par * ((this holes playcount)/(total hole one playcount)))
First_hole_Avg_Par <- sum(Pars$Hole1*(Playcounts$`n()` / sum(Playcounts$`n()`)))
Second_hole_Avg_Par <- sum(Pars$Hole2*(Playcounts$`n()` / sum(Playcounts$`n()`)))
Third_hole_Avg_Par <- sum(Pars$Hole3*(Playcounts$`n()` / sum(Playcounts$`n()`)))
Fourth_hole_Avg_Par <- sum(Pars$Hole4*(Playcounts$`n()` / sum(Playcounts$`n()`)))
Fifth_hole_Avg_Par <- sum(Pars$Hole5*(Playcounts$`n()` / sum(Playcounts$`n()`)))
Sixth_hole_Avg_Par <- sum(Pars$Hole6*(Playcounts$`n()` / sum(Playcounts$`n()`)))
Seventh_hole_Avg_Par <- sum(Pars$Hole7*(Playcounts$`n()` / sum(Playcounts$`n()`)))
Eighth_hole_Avg_Par <- sum(Pars$Hole8*(Playcounts$`n()` / sum(Playcounts$`n()`)))
Ninth_hole_Avg_Par <- sum(Pars$Hole9*(Playcounts$`n()` / sum(Playcounts$`n()`)))
#assign values to vector
Front_Nine_Avg_Pars <- c(First_hole_Avg_Par, Second_hole_Avg_Par, Third_hole_Avg_Par, Fourth_hole_Avg_Par, Fifth_hole_Avg_Par, Sixth_hole_Avg_Par, Seventh_hole_Avg_Par, Eighth_hole_Avg_Par, Ninth_hole_Avg_Par)
Front_Nine_Avg_Pars
Rel_Score <- (Front_Nine_Avgs - Front_Nine_Avg_Pars)
#get the ylimit to have extra space on the bottom, for labels
Ylim_One <- min(Front_Nine_Avgs-.03)
Ylim_Two <- max(Front_Nine_Avgs)
ggplot(data = df, aes(x = 1:9, y = Front_Nine_Avgs, label = Rel_Score), xlims = c(1,9), ylims = c(Ylim_Rel_One, Ylim_Rel_Two) ) +
geom_point() +
labs(title = paste("Avg strokes on the nth hole for:", Just_One_Name ), x = "Hole #", y = "Avg Strokes (Lower is Better)")+
scale_x_continuous(breaks = seq(1,9 , by = 1)) +
scale_y_continuous(breaks = round(seq(Ylim_One, Ylim_Two, .1), digits=2)) +
geom_text(label = round(Front_Nine_Avgs, digits = 2), hjust = 0,nudge_x = -0.125, nudge_y = -0.03)
#Put Rel_Score into a data frame
df <- data.frame(Rel_Score, 1:9)
#get the ylimit to have extra space on the bottom, for labels
Ylim_One <- min(Front_Nine_Avgs-.03)
Ylim_Two <- max(Front_Nine_Avgs)
ggplot(data = df, aes(x = 1:9, y = Front_Nine_Avgs, label = Rel_Score), xlims = c(1,9), ylims = c(Ylim_Rel_One, Ylim_Rel_Two) ) +
geom_point() +
labs(title = paste("Avg strokes on the nth hole for:", Just_One_Name ), x = "Hole #", y = "Avg Strokes (Lower is Better)")+
scale_x_continuous(breaks = seq(1,9 , by = 1)) +
scale_y_continuous(breaks = round(seq(Ylim_One, Ylim_Two, .1), digits=2)) +
geom_text(label = round(Front_Nine_Avgs, digits = 2), hjust = 0,nudge_x = -0.125, nudge_y = -0.03)
Ylim_Rel_One <- min(Rel_Score-.03)
Ylim_Rel_Two <- max(Rel_Score)
ggplot(data = df, aes(x = 1:9, y = Rel_Score, label = Rel_Score), xlims = c(1,9), ylims = c(Ylim_Rel_One, Ylim_Rel_Two) ) +
geom_point() +
labs(title = paste("Avg score on the nth hole for:", Just_One_Name ), x = "Hole #", y = "Avg Score (Lower is Better)")+
scale_x_continuous(breaks = seq(1,9 , by = 1)) +
scale_y_continuous(breaks = round(seq(Ylim_Rel_One, Ylim_Rel_Two, .1), digits=2)) +
geom_text(label = round(Rel_Score, digits = 2), hjust = 0,nudge_x = -0.125, nudge_y = -0.03)
setwd("E:/Obsidian vault/Personal Notes/R/Projects/UDISC-WRPPED/docs")
udisc_path <- "E:\\Obsidian vault\\Personal Notes\\R\\Projects\\UDISC\\Stats\\Dad2-23-2023.csv"
udisc_stats <- read.csv(udisc_path)
#creating primary key
udisc_stats <- mutate(udisc_stats,
Course_ID = paste(udisc_stats$CourseName, ": ", udisc_stats$LayoutName, ": "))
udisc_path <- "E:\\Obsidian vault\\Personal Notes\\R\\Projects\\UDISC\\Stats\\Dad2-23-2023.csv"
udisc_stats <- read.csv(udisc_path)
#creating primary key
udisc_stats <- mutate(udisc_stats,
Course_ID = paste(udisc_stats$CourseName, ": ", udisc_stats$LayoutName, ": "))
summary(udisc_stats)
udisc_path <- "E:\\Obsidian vault\\Personal Notes\\R\\Projects\\UDISC\\Stats\\Dad2-23-2023.csv"
udisc_stats <- read.csv(udisc_path)
#creating primary key
udisc_stats <- mutate(udisc_stats,
Course_ID = paste(udisc_stats$CourseName, ": ", udisc_stats$LayoutName, ": "))
summary(udisc_stats)
unlink("UDisc notebook_cache", recursive = TRUE)
udisc_path <- "E:\\Obsidian vault\\Personal Notes\\R\\Projects\\UDISC\\Stats\\Dad2-23-2023.csv"
udisc_stats <- read.csv(udisc_path)
udisc_stats <- mutate(udisc_stats,
Course_ID = paste(udisc_stats$CourseName, ": ", udisc_stats$LayoutName, ": "))
knit_with_parameters("E:/Obsidian vault/Personal Notes/R/Projects/UDISC-WRPPED/docs/UDisc notebook.Rmd")
